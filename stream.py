import subprocess
import logging
import config
import os
import time
import threading
import random
import requests
from urllib.parse import urljoin, urlparse, parse_qs
from anti_detection import AntiDetection

logger = logging.getLogger(__name__)

class StreamManager:
    def __init__(self):
        self.process = None
        self.is_running = False
        self.anti_detect = AntiDetection()
        self.monitor_thread = None
        self.current_source_type = None
        self.reconnect_count = 0
        self.max_reconnects = 50

    def detect_source_type(self, url):
        """Ø§ÙƒØªØ´Ø§Ù Ù†ÙˆØ¹ Ø§Ù„Ù…ØµØ¯Ø± Ø¨Ø¯Ù‚Ø©"""
        url_lower = url.lower()
        parsed = urlparse(url)
        
        # Periscope / Twitter
        if 'pscp.tv' in url_lower or 'periscope' in url_lower:
            return 'periscope'
        
        # TS Ù…Ø¨Ø§Ø´Ø± (Ø±ÙˆØ§Ø¨Ø· token Ù…Ø«Ù„ chervx)
        if 'token=' in url_lower or parsed.path.endswith('.ts'):
            return 'ts_direct'
        
        # Ù‚Ù†ÙˆØ§Øª Ø±ÙŠØ§Ø¶ÙŠØ© (Ù…Ø«Ù„ alkass, beIN, etc)
        sports_domains = ['alkass', 'bein', 'ssc', 'shahid', 'mbc']
        if any(domain in url_lower for domain in sports_domains):
            return 'sports_channel'
        
        # HLS Ø¹Ø§Ø¯ÙŠ
        if '.m3u8' in url_lower:
            return 'hls_standard'
        
        # MPEG-TS
        if 'mpegts' in url_lower or '/ts/' in url_lower:
            return 'mpegts'
        
        return 'unknown'

    def get_headers_for_source(self, source_type, url):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Headers Ù…Ù†Ø§Ø³Ø¨Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…ØµØ¯Ø±"""
        base_headers = {
            'User-Agent': self.anti_detect.get_random_user_agent(),
            'Accept': '*/*',
            'Accept-Language': 'ar,en-US;q=0.9,en;q=0.8',
            'Connection': 'keep-alive',
        }
        
        if source_type == 'periscope':
            base_headers.update({
                'Referer': 'https://twitter.com/',
                'Origin': 'https://twitter.com',
                'Sec-Fetch-Dest': 'empty',
                'Sec-Fetch-Mode': 'cors',
                'Sec-Fetch-Site': 'cross-site',
            })
        elif source_type == 'sports_channel':
            parsed = urlparse(url)
            base_headers.update({
                'Referer': f'{parsed.scheme}://{parsed.netloc}/',
                'Origin': f'{parsed.scheme}://{parsed.netloc}',
            })
        elif source_type == 'ts_direct':
            parsed = urlparse(url)
            base_headers.update({
                'Referer': f'{parsed.scheme}://{parsed.netloc}/',
                'Accept-Encoding': 'identity',
            })
        
        return base_headers

    def build_ffmpeg_command(self, source_url, stream_key, logo_path=None, quality='ultra'):
        """Ø¨Ù†Ø§Ø¡ Ø£Ù…Ø± FFmpeg Ù…Ø­Ø³Ù‘Ù† Ù„Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±"""
        rtmp_url = f"rtmps://live-api-s.facebook.com:443/rtmp/{stream_key}"
        
        # Ø§ÙƒØªØ´Ø§Ù Ù†ÙˆØ¹ Ø§Ù„Ù…ØµØ¯Ø±
        source_type = self.detect_source_type(source_url)
        self.current_source_type = source_type
        
        logger.info(f"ğŸ“¡ Ù†ÙˆØ¹ Ø§Ù„Ù…ØµØ¯Ø±: {source_type}")
        logger.info(f"ğŸ“Š Ø§Ù„Ø¬ÙˆØ¯Ø©: {quality.upper()}")
        
        # ØªØ­Ø³ÙŠÙ† Ø±Ø§Ø¨Ø· Periscope
        if source_type == 'periscope':
            source_url = self.optimize_periscope_url(source_url)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Headers
        headers = self.get_headers_for_source(source_type, source_url)
        
        command = [
            'ffmpeg',
            '-hide_banner',
            '-loglevel', 'warning',
            '-y',
        ]
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…ØµØ¯Ø±
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        if source_type == 'ts_direct':
            # TS Ù…Ø¨Ø§Ø´Ø± - Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø®Ø§ØµØ©
            command.extend([
                '-re',
                '-timeout', '10000000',
                '-rw_timeout', '10000000',
                '-reconnect', '1',
                '-reconnect_streamed', '1',
                '-reconnect_delay_max', '5',
                '-user_agent', headers['User-Agent'],
            ])
            if 'Referer' in headers:
                command.extend(['-referer', headers['Referer']])
            command.extend([
                '-i', source_url,
            ])
            
        elif source_type == 'periscope':
            # Periscope/Twitter - Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø³Ù‘Ù†Ø©
            command.extend([
                '-multiple_requests', '1',
                '-reconnect', '1',
                '-reconnect_streamed', '1',
                '-reconnect_at_eof', '1',
                '-reconnect_on_network_error', '1',
                '-reconnect_on_http_error', '4xx,5xx',
                '-reconnect_delay_max', '3',
                '-analyzeduration', '5000000',
                '-probesize', '5000000',
                '-fflags', '+genpts+discardcorrupt+nobuffer+flush_packets',
                '-timeout', '10000000',
                '-rw_timeout', '10000000',
                '-protocol_whitelist', 'file,http,https,tcp,tls,crypto,hls',
                '-tls_verify', '0',
                '-user_agent', headers['User-Agent'],
                '-headers', f"Referer: {headers.get('Referer', 'https://twitter.com/')}\r\nOrigin: {headers.get('Origin', 'https://twitter.com')}\r\n",
                '-i', source_url,
            ])
            
        elif source_type == 'sports_channel':
            # Ù‚Ù†ÙˆØ§Øª Ø±ÙŠØ§Ø¶ÙŠØ© - Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¹Ø§Ù„ÙŠ
            command.extend([
                '-multiple_requests', '1',
                '-reconnect', '1',
                '-reconnect_streamed', '1',
                '-reconnect_at_eof', '1',
                '-reconnect_on_network_error', '1',
                '-reconnect_on_http_error', '4xx,5xx',
                '-reconnect_delay_max', '2',
                '-analyzeduration', '3000000',
                '-probesize', '3000000',
                '-fflags', '+genpts+discardcorrupt+nobuffer+flush_packets+igndts',
                '-timeout', '8000000',
                '-rw_timeout', '8000000',
                '-protocol_whitelist', 'file,http,https,tcp,tls,crypto,hls',
                '-tls_verify', '0',
                '-user_agent', headers['User-Agent'],
            ])
            if 'Referer' in headers:
                command.extend(['-referer', headers['Referer']])
            command.extend(['-i', source_url])
            
        else:
            # HLS Ø¹Ø§Ø¯ÙŠ Ø£Ùˆ Ù…ØµØ§Ø¯Ø± Ø£Ø®Ø±Ù‰
            command.extend([
                '-multiple_requests', '1',
                '-reconnect', '1',
                '-reconnect_streamed', '1',
                '-reconnect_at_eof', '1',
                '-reconnect_on_network_error', '1',
                '-reconnect_on_http_error', '4xx,5xx',
                '-reconnect_delay_max', '2',
                '-analyzeduration', '2000000',
                '-probesize', '2000000',
                '-fflags', '+genpts+discardcorrupt+nobuffer+flush_packets',
                '-timeout', '5000000',
                '-rw_timeout', '5000000',
                '-protocol_whitelist', 'file,http,https,tcp,tls,crypto,hls',
                '-tls_verify', '0',
                '-user_agent', headers['User-Agent'],
                '-i', source_url,
            ])
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù„ÙˆØ¬Ùˆ Ø¥Ù† ÙˆØ¬Ø¯
        if logo_path and os.path.exists(logo_path):
            command.extend(['-i', logo_path])
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø¬ÙˆØ¯Ø©
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        quality_settings = self.get_quality_settings(quality)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ±Ù…ÙŠØ² (OUTPUT)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        command.extend([
            '-c:v', 'libx264',
            '-preset', 'ultrafast',
            '-tune', 'zerolatency',
            '-profile:v', 'high',
            '-level', '4.1',
            '-b:v', quality_settings['bitrate'],
            '-maxrate', quality_settings['maxrate'],
            '-bufsize', quality_settings['bufsize'],
            '-pix_fmt', 'yuv420p',
            '-g', '60',
            '-keyint_min', '30',
            '-sc_threshold', '0',
            '-force_key_frames', 'expr:gte(t,n_forced*2)',
        ])
        
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØµÙˆØª
        command.extend([
            '-c:a', 'aac',
            '-b:a', quality_settings['audio_bitrate'],
            '-ar', '44100',
            '-ac', '2',
            '-af', 'aresample=async=1:min_hard_comp=0.100000:first_pts=0',
        ])
        
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ RTMP
        command.extend([
            '-f', 'flv',
            '-flvflags', 'no_duration_filesize+no_metadata',
            '-max_muxing_queue_size', '2048',
            '-flush_packets', '1',
            '-rtmp_buffer', '1500',
            '-rtmp_live', 'live',
            rtmp_url
        ])
        
        return command

    def optimize_periscope_url(self, url):
        """ØªØ­Ø³ÙŠÙ† Ø±Ø§Ø¨Ø· Periscope Ù„Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±"""
        # ØªØ­ÙˆÙŠÙ„ Ù…Ù† transcode Ø¥Ù„Ù‰ non_transcode Ù„Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±
        if 'transcode/' in url and 'dynamic_highlatency.m3u8' in url:
            url = url.replace('/transcode/', '/non_transcode/')
            url = url.replace('dynamic_highlatency.m3u8', 'master_dynamic_highlatency.m3u8')
            logger.info("ğŸ”„ ØªØ­ÙˆÙŠÙ„ Periscope Ø¥Ù„Ù‰ master playlist")
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ù†ÙØ° Ø§Ù„Ø²Ø§Ø¦Ø¯
        url = url.replace(':443/', '/')
        
        return url

    def get_quality_settings(self, quality):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¬ÙˆØ¯Ø©"""
        settings = {
            'ultra': {
                'bitrate': '5000k',
                'maxrate': '6000k',
                'bufsize': '10000k',
                'audio_bitrate': '192k'
            },
            'high': {
                'bitrate': '4500k',
                'maxrate': '5000k',
                'bufsize': '9000k',
                'audio_bitrate': '160k'
            },
            'medium': {
                'bitrate': '3000k',
                'maxrate': '3500k',
                'bufsize': '6000k',
                'audio_bitrate': '128k'
            },
            'low': {
                'bitrate': '2000k',
                'maxrate': '2500k',
                'bufsize': '4000k',
                'audio_bitrate': '96k'
            }
        }
        return settings.get(quality.lower(), settings['ultra'])

    def validate_source(self, url):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ù…ØµØ¯Ø±"""
        try:
            source_type = self.detect_source_type(url)
            headers = self.get_headers_for_source(source_type, url)
            
            response = requests.head(url, headers=headers, timeout=10, verify=False, allow_redirects=True)
            
            if response.status_code == 200:
                return True, source_type
            elif response.status_code == 405:
                # Ø¨Ø¹Ø¶ Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª Ù„Ø§ ØªØ¯Ø¹Ù… HEADØŒ Ù†Ø¬Ø±Ø¨ GET
                response = requests.get(url, headers=headers, timeout=10, verify=False, stream=True)
                response.close()
                return response.status_code == 200, source_type
            else:
                return False, source_type
                
        except Exception as e:
            logger.warning(f"âš ï¸ ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±: {e}")
            return True, self.detect_source_type(url)  # Ù†Ø¹ØªØ¨Ø±Ù‡ ØµØ§Ù„Ø­ ÙˆÙ†ØªØ±Ùƒ FFmpeg ÙŠØªØ¹Ø§Ù…Ù„

    def start_stream(self, source_url, rtmp_url, stream_key, logo_path=None, quality='ultra'):
        """Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø« Ù…Ø¹ ØªÙ‚Ù†ÙŠØ§Øª ØªØ¬Ù†Ø¨ Ø§Ù„ÙƒØ´Ù"""
        if self.process and self.process.poll() is None:
            return False, "âš ï¸ Ø§Ù„Ø¨Ø« ÙŠØ¹Ù…Ù„ Ø¨Ø§Ù„ÙØ¹Ù„!"
        
        self.is_running = False
        self.process = None
        self.reconnect_count = 0
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±
        logger.info("ğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±...")
        is_valid, source_type = self.validate_source(source_url)
        
        if not is_valid:
            return False, f"âŒ Ø§Ù„Ù…ØµØ¯Ø± ØºÙŠØ± Ù…ØªØ§Ø­!\n\nØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø±Ø§Ø¨Ø·."
        
        logger.info(f"âœ… Ø§Ù„Ù…ØµØ¯Ø± Ù…ØªØ§Ø­ ({source_type})")
        
        # ØªÙØ¹ÙŠÙ„ ØªÙ‚Ù†ÙŠØ§Øª ØªØ¬Ù†Ø¨ Ø§Ù„ÙƒØ´Ù
        logger.info("ğŸ” ØªÙØ¹ÙŠÙ„ ØªÙ‚Ù†ÙŠØ§Øª ØªØ¬Ù†Ø¨ Ø§Ù„ÙƒØ´Ù...")
        self.anti_detect.apply_stream_spacing()
        time.sleep(random.uniform(1, 2))
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø£Ù…Ø±
        command = self.build_ffmpeg_command(source_url, stream_key, logo_path, quality=quality)
        
        logger.info(f"ğŸ“º Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø«...")
        logger.info(f"ğŸ“ Ø§Ù„Ù…ØµØ¯Ø±: {source_url[:60]}...")
        
        try:
            # ØªØ´ØºÙŠÙ„ FFmpeg
            self.process = subprocess.Popen(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1
            )
            
            logger.info(f"âœ… FFmpeg Ø¨Ø¯Ø£ (PID: {self.process.pid})")
            
            # Ø§Ù†ØªØ¸Ø± Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„
            time.sleep(5)
            
            if self.process.poll() is not None:
                stdout, stderr = self.process.communicate(timeout=2)
                logger.error(f"âŒ FFmpeg ÙØ´Ù„: {stderr[:500] if stderr else 'No error output'}")
                self.process = None
                
                error_msg = self.parse_ffmpeg_error(stderr)
                return False, error_msg
            
            # Ø§Ù†ØªØ¸Ø± Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„ØªØ£ÙƒØ¯
            time.sleep(5)
            
            if self.process.poll() is not None:
                stdout, stderr = self.process.communicate(timeout=2)
                error_msg = self.parse_ffmpeg_error(stderr)
                return False, error_msg
            
            self.is_running = True
            
            # Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
            self.monitor_thread = threading.Thread(target=self._monitor, daemon=True)
            self.monitor_thread.start()
            
            source_name = {
                'periscope': 'Twitter/Periscope',
                'ts_direct': 'TS Ù…Ø¨Ø§Ø´Ø±',
                'sports_channel': 'Ù‚Ù†Ø§Ø© Ø±ÙŠØ§Ø¶ÙŠØ©',
                'hls_standard': 'HLS',
                'mpegts': 'MPEG-TS'
            }.get(source_type, 'Ø¹Ø§Ø¯ÙŠ')
            
            return True, f"âœ… Ø§Ù„Ø¨Ø« ÙŠØ¹Ù…Ù„!\n\nğŸ“¡ Ø§Ù„Ù†ÙˆØ¹: {source_name}\nğŸ›¡ï¸ Ø­Ù…Ø§ÙŠØ© Ù…ÙØ¹Ù„Ø©\nğŸ“º Ø§ÙØªØ­ ØµÙØ­Ø© Ø§Ù„Ø¨Ø« ÙÙŠ Facebook\nâ±ï¸ ÙŠØ¬Ø¨ Ø£Ù† ØªØ±Ø§Ù‡ ÙÙŠ Ø«ÙˆØ§Ù†Ù\n\nØ§Ø³ØªØ®Ø¯Ù… /stop Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø«."
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£: {e}")
            self.process = None
            return False, f"âŒ Ø®Ø·Ø£: {str(e)}"

    def parse_ffmpeg_error(self, stderr):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ø®Ø·Ø§Ø¡ FFmpeg ÙˆØªØ±Ø¬Ù…ØªÙ‡Ø§"""
        if not stderr:
            return "âŒ Ø§Ù„Ø¨Ø« ÙØ´Ù„!\n\nØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ØµØ­ÙŠØ­."
        
        stderr_lower = stderr.lower()
        
        if "mime type is not rfc8216" in stderr_lower:
            return "âŒ ØµÙŠØºØ© Ø§Ù„Ø¨Ø« ØºÙŠØ± Ù…Ø¹ÙŠØ§Ø±ÙŠØ©!\n\nØ¬Ø±Ø¨ Ø±Ø§Ø¨Ø· M3U8 Ø¢Ø®Ø±."
        elif "connection refused" in stderr_lower or "refused" in stderr_lower:
            return "âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Facebook!\n\nØªØ£ÙƒØ¯ Ù…Ù† Stream Key ØµØ­ÙŠØ­ ÙˆØ¬Ø¯ÙŠØ¯."
        elif "403" in stderr or "forbidden" in stderr_lower:
            return "âŒ Ø§Ù„ÙˆØµÙˆÙ„ Ù…Ø±ÙÙˆØ¶!\n\nØ§Ù„Ø±Ø§Ø¨Ø· Ù…Ø­Ù…ÙŠ Ø£Ùˆ Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©."
        elif "404" in stderr or "not found" in stderr_lower:
            return "âŒ Ø§Ù„Ø±Ø§Ø¨Ø· ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!\n\nØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø±Ø§Ø¨Ø·."
        elif "timeout" in stderr_lower:
            return "âŒ Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„!\n\nØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ÙˆØ§Ù„Ø±Ø§Ø¨Ø·."
        elif "invalid data" in stderr_lower or "invalid stream" in stderr_lower:
            return "âŒ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ§Ù„Ø­Ø©!\n\nØ§Ù„Ø±Ø§Ø¨Ø· Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨Ø« ØµØ§Ù„Ø­."
        elif "no route to host" in stderr_lower:
            return "âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø³ÙŠØ±ÙØ±!\n\nØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª."
        else:
            return f"âŒ Ø§Ù„Ø¨Ø« ÙØ´Ù„!\n\nØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ØµØ­ÙŠØ­.\n\n{stderr[:200]}"

    def _monitor(self):
        """Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¨Ø« Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§ØªØµØ§Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"""
        while self.is_running and self.process:
            if self.process.poll() is not None:
                logger.warning("âš ï¸ Ø§Ù„Ø¨Ø« ØªÙˆÙ‚Ù")
                self.is_running = False
                break
            time.sleep(5)

    def stop_stream(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø«"""
        self.is_running = False
        
        if self.process and self.process.poll() is None:
            try:
                self.process.terminate()
                try:
                    self.process.wait(timeout=3)
                except:
                    self.process.kill()
            except:
                pass
            self.process = None
        
        return True, "âœ… ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø«."

    def get_status(self):
        """Ø­Ø§Ù„Ø© Ø§Ù„Ø¨Ø«"""
        if self.process and self.process.poll() is None:
            return {'active': True, 'source_type': self.current_source_type}
        self.is_running = False
        return {'active': False}

    def get_detailed_status(self):
        """Ø­Ø§Ù„Ø© Ù…ÙØµÙ„Ø©"""
        status = self.get_status()
        if status['active']:
            source_type_value = status.get('source_type') or ''
            source_names = {
                'periscope': 'Twitter/Periscope',
                'ts_direct': 'TS Ù…Ø¨Ø§Ø´Ø±',
                'sports_channel': 'Ù‚Ù†Ø§Ø© Ø±ÙŠØ§Ø¶ÙŠØ©',
                'hls_standard': 'HLS',
                'mpegts': 'MPEG-TS'
            }
            source_name = source_names.get(str(source_type_value), 'Ø¹Ø§Ø¯ÙŠ')
            return f"âœ… Ø§Ù„Ø¨Ø« Ù†Ø´Ø· ğŸ›¡ï¸\nğŸ“¡ Ø§Ù„Ù†ÙˆØ¹: {source_name}\nğŸ” Ø­Ù…Ø§ÙŠØ©: Ù…ÙØ¹Ù„Ø©"
        return "âŒ Ø§Ù„Ø¨Ø« Ù…ØªÙˆÙ‚Ù"

    def parse_m3u8_for_best_quality(self, m3u8_url):
        """ØªØ­Ù„ÙŠÙ„ M3U8 ÙˆØ§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ø¬ÙˆØ¯Ø©"""
        source_type = self.detect_source_type(m3u8_url)
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† TS Ù…Ø¨Ø§Ø´Ø±ØŒ Ù„Ø§ Ù†Ø­ØªØ§Ø¬ ØªØ­Ù„ÙŠÙ„
        if source_type == 'ts_direct':
            logger.info("ğŸ“¡ TS Ù…Ø¨Ø§Ø´Ø± - Ù„Ø§ ÙŠØ­ØªØ§Ø¬ ØªØ­Ù„ÙŠÙ„")
            return m3u8_url
        
        try:
            headers = self.get_headers_for_source(source_type, m3u8_url)
            
            response = requests.get(m3u8_url, headers=headers, timeout=15, verify=False)
            response.raise_for_status()
            content = response.text
            
            # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† master playlist
            if '#EXT-X-STREAM-INF' not in content:
                logger.info("ğŸ“¡ Single quality stream")
                return m3u8_url
            
            bitrates = {}
            lines = content.split('\n')
            
            for i, line in enumerate(lines):
                if 'EXT-X-STREAM-INF' in line and 'BANDWIDTH=' in line:
                    try:
                        bandwidth = int(line.split('BANDWIDTH=')[1].split(',')[0])
                        if i + 1 < len(lines):
                            next_line = lines[i + 1].strip()
                            if next_line and not next_line.startswith('#'):
                                if next_line.startswith('http'):
                                    bitrates[bandwidth] = next_line
                                else:
                                    base_url = m3u8_url.rsplit('/', 1)[0]
                                    bitrates[bandwidth] = urljoin(base_url + '/', next_line)
                    except Exception as e:
                        logger.debug(f"Error parsing bandwidth: {e}")
                        pass
            
            if bitrates:
                best_bandwidth = max(bitrates.keys())
                logger.info(f"ğŸ¬ M3U8: {len(bitrates)} Ø¬ÙˆØ¯Ø§ØªØŒ Ø§Ø®ØªÙŠØ§Ø± {best_bandwidth/1000:.0f}k")
                return bitrates[best_bandwidth]
            
        except Exception as e:
            logger.warning(f"âš ï¸ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù„ÙŠÙ„ M3U8: {e}")
        
        return m3u8_url
